{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68a75440",
   "metadata": {},
   "source": [
    "# Australian Steam Recommendation – Baselines and Stronger Model\n",
    "\n",
    "This notebook assumes you have already created `australian_steam_merged.csv` from the data-prep notebook.\n",
    "\n",
    "We will:\n",
    "1. Load the merged dataset\n",
    "2. Build **text-only baselines**:\n",
    "   - Majority class baseline\n",
    "   - TF-IDF + Naive Bayes\n",
    "   - TF-IDF + Logistic Regression\n",
    "3. Build a **stronger model** that combines:\n",
    "   - TF-IDF text features\n",
    "   - Numeric user–item and game features (e.g., playtime, items_count, price, metascore)\n",
    "4. Compare models using Accuracy, F1, Macro-F1, and ROC-AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 180)\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d735112",
   "metadata": {},
   "source": [
    "## 1. Load Merged Dataset\n",
    "\n",
    "We start from the preprocessed file `australian_steam_merged.csv`, where each row is a review with:\n",
    "- `review_text`\n",
    "- `label` (0/1 for not recommended / recommended)\n",
    "- user–item features (`playtime_forever`, `playtime_2weeks`, `items_count`)\n",
    "- game features (`price`, `metascore`, etc., depending on availability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89974fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('australian_steam_merged.csv')\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f'Cannot find {data_path}. Please run the data prep notebook first.')\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print('Loaded merged dataset with shape:', df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e356152",
   "metadata": {},
   "source": [
    "## 2. Basic Cleaning and Train/Test Split\n",
    "\n",
    "We keep rows with non-null `review_text` and `label`, then create an 80/20 train/test split.\n",
    "We stratify by the label due to the strong class imbalance (most reviews are positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing text or label\n",
    "df = df.dropna(subset=['review_text', 'label']).copy()\n",
    "df['review_text'] = df['review_text'].astype(str)\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "print('After cleaning:', df.shape)\n",
    "print('Label distribution:')\n",
    "print(df['label'].value_counts(normalize=True))\n",
    "\n",
    "X_text = df['review_text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_text, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "print('Train size:', len(X_train))\n",
    "print('Test size:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178aa091",
   "metadata": {},
   "source": [
    "## 3. TF-IDF Text Representation\n",
    "\n",
    "We represent `review_text` using a TF-IDF bag-of-words model with unigrams and bigrams.\n",
    "This will be reused across all text-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0d488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features=50_000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=3,\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print('TF-IDF train shape:', X_train_tfidf.shape)\n",
    "print('TF-IDF test shape:', X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1608e9",
   "metadata": {},
   "source": [
    "## 4. Baseline 1 – Majority Class Predictor\n",
    "\n",
    "We first consider a trivial baseline that always predicts the most frequent class in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb009c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "majority_class = y_train.mode()[0]\n",
    "y_pred_majority = np.full_like(y_test, fill_value=majority_class)\n",
    "\n",
    "acc_majority = accuracy_score(y_test, y_pred_majority)\n",
    "f1_majority = f1_score(y_test, y_pred_majority)\n",
    "f1_macro_majority = f1_score(y_test, y_pred_majority, average='macro')\n",
    "\n",
    "print('Majority baseline:')\n",
    "print('  Accuracy   :', acc_majority)\n",
    "print('  F1 (pos)   :', f1_majority)\n",
    "print('  F1 macro   :', f1_macro_majority)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b63b7",
   "metadata": {},
   "source": [
    "## 5. Baseline 2 – TF-IDF + Naive Bayes\n",
    "\n",
    "Next, we train a Multinomial Naive Bayes classifier on the TF-IDF features. This is a classic baseline for text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_nb = nb.predict(X_test_tfidf)\n",
    "y_prob_nb = nb.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "acc_nb = accuracy_score(y_test, y_pred_nb)\n",
    "f1_nb = f1_score(y_test, y_pred_nb)\n",
    "f1_macro_nb = f1_score(y_test, y_pred_nb, average='macro')\n",
    "roc_nb = roc_auc_score(y_test, y_prob_nb)\n",
    "\n",
    "print('Naive Bayes:')\n",
    "print('  Accuracy   :', acc_nb)\n",
    "print('  F1 (pos)   :', f1_nb)\n",
    "print('  F1 macro   :', f1_macro_nb)\n",
    "print('  ROC-AUC    :', roc_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93392a8e",
   "metadata": {},
   "source": [
    "## 6. Baseline 3 – TF-IDF + Logistic Regression (Text Only)\n",
    "\n",
    "We now train a logistic regression classifier on the TF-IDF features only. This is typically a strong baseline for text classification and provides a good reference point for more complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7279444",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr_text = LogisticRegression(max_iter=2000, n_jobs=-1)\n",
    "clf_lr_text.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_lr = clf_lr_text.predict(X_test_tfidf)\n",
    "y_prob_lr = clf_lr_text.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "f1_macro_lr = f1_score(y_test, y_pred_lr, average='macro')\n",
    "roc_lr = roc_auc_score(y_test, y_prob_lr)\n",
    "\n",
    "print('Logistic Regression (text only):')\n",
    "print('  Accuracy   :', acc_lr)\n",
    "print('  F1 (pos)   :', f1_lr)\n",
    "print('  F1 macro   :', f1_macro_lr)\n",
    "print('  ROC-AUC    :', roc_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a201c630",
   "metadata": {},
   "source": [
    "## 7. Stronger Model – TF-IDF + Numeric Features (User–Item + Game)\n",
    "\n",
    "To build a stronger model, we augment the TF-IDF text representation with numeric features such as:\n",
    "- `playtime_forever`, `playtime_2weeks`\n",
    "- `items_count`\n",
    "- `price`, `metascore` (if available)\n",
    "\n",
    "We then train a single logistic regression model on the concatenated feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa271439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric feature columns that exist in the dataset\n",
    "candidate_num_cols = ['playtime_forever', 'playtime_2weeks', 'items_count', 'price', 'metascore']\n",
    "num_cols = [c for c in candidate_num_cols if c in df.columns]\n",
    "\n",
    "print('Base numeric feature columns:', num_cols)\n",
    "\n",
    "# Fill missing values with 0\n",
    "df[num_cols] = df[num_cols].fillna(0)\n",
    "\n",
    "# Optional: add log-transformed versions for skewed features\n",
    "for col in ['playtime_forever', 'playtime_2weeks']:\n",
    "    if col in df.columns:\n",
    "        log_col = 'log_' + col\n",
    "        df[log_col] = np.log1p(df[col])\n",
    "        num_cols.append(log_col)\n",
    "\n",
    "print('Final numeric feature columns:', num_cols)\n",
    "\n",
    "# Align numeric features with train/test splits using the same indices as X_train/X_test\n",
    "X_train_num = df.loc[X_train.index, num_cols].values\n",
    "X_test_num = df.loc[X_test.index, num_cols].values\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train_num)\n",
    "X_test_num_scaled = scaler.transform(X_test_num)\n",
    "\n",
    "print('Numeric train shape:', X_train_num_scaled.shape)\n",
    "print('Numeric test shape:', X_test_num_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fd21c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine TF-IDF (sparse) and numeric (dense) features\n",
    "X_train_full = hstack([X_train_tfidf, X_train_num_scaled])\n",
    "X_test_full = hstack([X_test_tfidf, X_test_num_scaled])\n",
    "\n",
    "print('Combined train shape:', X_train_full.shape)\n",
    "print('Combined test shape:', X_test_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f20cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression on combined features\n",
    "clf_full = LogisticRegression(max_iter=2000, n_jobs=-1)\n",
    "clf_full.fit(X_train_full, y_train)\n",
    "\n",
    "y_pred_full = clf_full.predict(X_test_full)\n",
    "y_prob_full = clf_full.predict_proba(X_test_full)[:, 1]\n",
    "\n",
    "acc_full = accuracy_score(y_test, y_pred_full)\n",
    "f1_full = f1_score(y_test, y_pred_full)\n",
    "f1_macro_full = f1_score(y_test, y_pred_full, average='macro')\n",
    "roc_full = roc_auc_score(y_test, y_prob_full)\n",
    "\n",
    "print('Stronger model (TF-IDF + numeric features):')\n",
    "print('  Accuracy   :', acc_full)\n",
    "print('  F1 (pos)   :', f1_full)\n",
    "print('  F1 macro   :', f1_macro_full)\n",
    "print('  ROC-AUC    :', roc_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3596f4a",
   "metadata": {},
   "source": [
    "## 8. Model Comparison Table\n",
    "\n",
    "Finally, we summarize the performance of all models in a single table. This is suitable for inclusion in the report and presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e63af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\n",
    "    ['Majority', acc_majority, f1_majority, f1_macro_majority, None],\n",
    "    ['TF-IDF + Naive Bayes', acc_nb, f1_nb, f1_macro_nb, roc_nb],\n",
    "    ['TF-IDF + Logistic Regression (text only)', acc_lr, f1_lr, f1_macro_lr, roc_lr],\n",
    "    ['TF-IDF + Logistic Regression (text + numeric)', acc_full, f1_full, f1_macro_full, roc_full],\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'F1 (pos)', 'F1 macro', 'ROC-AUC'])\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
